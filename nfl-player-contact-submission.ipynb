{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0f3314",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-22T20:54:27.118946Z",
     "iopub.status.busy": "2023-02-22T20:54:27.118496Z",
     "iopub.status.idle": "2023-02-22T20:54:31.394688Z",
     "shell.execute_reply": "2023-02-22T20:54:31.393693Z"
    },
    "papermill": {
     "duration": 4.28463,
     "end_time": "2023-02-22T20:54:31.397212",
     "exception": false,
     "start_time": "2023-02-22T20:54:27.112582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "shutil.copytree('/kaggle/input/packages/fvcore', 'fvcore')\n",
    "shutil.copytree('/kaggle/input/packages/iopath', 'iopath')\n",
    "shutil.copytree('/kaggle/input/packages/pytorchvideo', 'pytorchvideo')\n",
    "shutil.copytree('/kaggle/input/packages/NFL-Player-Contact-Detection', 'NFL-Player-Contact-Detection')\n",
    "shutil.copytree('/kaggle/input/models', 'models')\n",
    "\n",
    "\n",
    "sys.path.append('/kaggle/working/NFL-Player-Contact-Detection')\n",
    "sys.path.append('/kaggle/working/models')\n",
    "sys.path.append('/kaggle/working/pytorchvideo')\n",
    "sys.path.append('/kaggle/working/fvcore')\n",
    "sys.path.append('/kaggle/working/iopath')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67ce9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:54:31.405545Z",
     "iopub.status.busy": "2023-02-22T20:54:31.405222Z",
     "iopub.status.idle": "2023-02-22T20:54:34.526329Z",
     "shell.execute_reply": "2023-02-22T20:54:34.525301Z"
    },
    "papermill": {
     "duration": 3.128369,
     "end_time": "2023-02-22T20:54:34.529296",
     "exception": false,
     "start_time": "2023-02-22T20:54:31.400927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score, classification_report\n",
    "\n",
    "from trainer import Trainer\n",
    "from frame_extraction import FrameExctracor, extract_parallel\n",
    "from models import FilterGRU, TransformerTracker \n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda:0':\n",
    "    print('GPU: ', torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3ce03",
   "metadata": {
    "papermill": {
     "duration": 0.003232,
     "end_time": "2023-02-22T20:54:34.536851",
     "exception": false,
     "start_time": "2023-02-22T20:54:34.533619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9469ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:54:34.545052Z",
     "iopub.status.busy": "2023-02-22T20:54:34.544611Z",
     "iopub.status.idle": "2023-02-22T20:54:35.113754Z",
     "shell.execute_reply": "2023-02-22T20:54:35.112830Z"
    },
    "papermill": {
     "duration": 0.57596,
     "end_time": "2023-02-22T20:54:35.116197",
     "exception": false,
     "start_time": "2023-02-22T20:54:34.540237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def create_image_dataset(source_dir, file_names = [], transform = None):\n",
    "    \n",
    "    if not file_names:\n",
    "        file_names = os.listdir(source_dir)\n",
    "        \n",
    "    i_paths = [f'{source_dir}/{p}' for p in file_names]\n",
    "    \n",
    "    image_data = datasets.Dataset\\\n",
    "        .from_dict({'file_path': i_paths})\\\n",
    "        .save_to_disk('image_data')\n",
    "    \n",
    "    image_data = datasets.Dataset.load_from_disk('image_data')\n",
    "\n",
    "    def load_imgs(examples):\n",
    "        imgs = []\n",
    "        for ex in examples['file_path']:\n",
    "            img = cv2.imread(ex)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img= torch.from_numpy(img).permute(2,0,1)\n",
    "            else:\n",
    "                img=torch.zeros(3,720,1280)\n",
    "            if transform is not None:\n",
    "                img = transform(img)\n",
    "                \n",
    "            b = io.BytesIO()\n",
    "            torch.save(img, b)\n",
    "            b.seek(0)\n",
    "            imgs.append(b.read())\n",
    "\n",
    "        return {'image': imgs}\n",
    "    \n",
    "    image_data = image_data.map(load_imgs, batched=True, batch_size=600)\n",
    "\n",
    "    path2index = {p.split(\"/\")[-1].replace(\".jpg\", \"\"):i for i, p in enumerate(image_data['file_path'])}\n",
    "    index2path, _ = zip(*sorted(path2index.items(), key=lambda x: x[1]))\n",
    "\n",
    "    def b2tensor(examples):\n",
    "        examples['image'] = [torch.load(io.BytesIO(image)) for image in examples['image']]\n",
    "        return examples\n",
    "\n",
    "    image_data.set_transform(b2tensor)\n",
    "    \n",
    "    return image_data, path2index, index2path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6553dd04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:54:35.125194Z",
     "iopub.status.busy": "2023-02-22T20:54:35.124751Z",
     "iopub.status.idle": "2023-02-22T20:54:35.155946Z",
     "shell.execute_reply": "2023-02-22T20:54:35.155105Z"
    },
    "papermill": {
     "duration": 0.037976,
     "end_time": "2023-02-22T20:54:35.157867",
     "exception": false,
     "start_time": "2023-02-22T20:54:35.119891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "keys = [ 'game_play',  'nfl_player_id_1', 'nfl_player_id_2', 'jersey_number_p1', 'position_p1', 'jersey_number_p2', 'position_p2', ]\n",
    "features = ['contact_id', 'frame', 'contact', 'step', \n",
    "            'acceleration_p1',  'acceleration_p2', 'speed_p2', 'speed_p1', 'sa_p1', 'sa_p2','dist', 'is_one_team', 'is_ground_contact']\n",
    "\n",
    "def agg_chanks_fn(df, chank_size):\n",
    "    res = {_: [] for _ in keys + features}\n",
    "\n",
    "    for d in np.array_split(df, len(df)//chank_size + 1):\n",
    "        if  not d.empty:\n",
    "            for k in keys:\n",
    "                res[k].append(d[k].iloc[0])\n",
    "            for f in features:\n",
    "                res[f].append(d[f].tolist())\n",
    "                \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "\n",
    "def create_tracking_features(labels, tracking, chank_size = None,\n",
    "                             dist_threshold = 4, speed_threshold= 4, \n",
    "                             keys=keys, features= features):\n",
    "    \n",
    "    p_df = labels.query('nfl_player_id_2 != \"G\"')\\\n",
    "            .merge(tracking.rename({'nfl_player_id': 'nfl_player_id_1'}, axis=1))\\\n",
    "            .merge(tracking.rename({'nfl_player_id': 'nfl_player_id_2'}, axis=1), \n",
    "                   on = ['game_play', 'game_key', 'play_id', 'datetime', 'step', 'frame', 'nfl_player_id_2'], \n",
    "                   suffixes=['_p1', '_p2'])\n",
    "\n",
    "\n",
    "    p_df['dist'] = np.sqrt((p_df.y_position_p1-p_df.y_position_p2)**2 + (p_df.x_position_p1-p_df.x_position_p2)**2)\n",
    "    p_df['is_one_team'] = (p_df.team_p1==p_df.team_p2).astype(int)\n",
    "    p_df = p_df.query(f\"dist<{dist_threshold}\")\n",
    "    p_df['is_ground_contact'] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ground contacts\n",
    "    g_df=labels.query('nfl_player_id_2 == \"G\"')\\\n",
    "        .merge(tracking.rename({'nfl_player_id': 'nfl_player_id_1'}, axis=1))\n",
    "        \n",
    "    g_df = g_df.query(f\"speed<{speed_threshold}\")\n",
    "    \n",
    "    g_df.columns = p_df.columns[:len(g_df.columns)]\n",
    "    g_df.loc[g_df.contact == 1, 'contact'] = 2\n",
    "    \n",
    "    g_df['is_ground_contact'] = 1\n",
    "    \n",
    "    \n",
    "    # put together\n",
    "    df = pd.concat([p_df,g_df])\\\n",
    "        .fillna(0)\\\n",
    "        .sort_values(keys + ['step'])\n",
    "    \n",
    "\n",
    "\n",
    "    if chank_size is not None:\n",
    "        df = df.groupby(keys, group_keys=False).apply(agg_chanks_fn, chank_size)     \n",
    "    else:\n",
    "        df = df.groupby(keys, as_index=False).agg(list)[keys+features]\n",
    "     \n",
    "    return df\n",
    "\n",
    "\n",
    "def crop_players(img, p1_id, p2_id, game_play, players, zone):\n",
    "    \n",
    "    mask = torch.zeros(img.shape)\n",
    "    show_list = players[players.nfl_player_id.isin([p1_id, p2_id]) & (players.view == zone)]\n",
    "    hide_list = players[~players.nfl_player_id.isin([p1_id, p2_id]) & (players.view == zone)]\n",
    "    \n",
    "    if show_list.empty:\n",
    "        return mask\n",
    "\n",
    "    xmin = 100000\n",
    "    xmax = 0\n",
    "    ymin = 100000\n",
    "    ymax = 0\n",
    "\n",
    "    for i, p in show_list.iterrows():\n",
    "        x1 = int(p.left - 2*p.width)\n",
    "        x2 = int(p.left + 5*p.width)\n",
    "        y1 = int(p.top)\n",
    "        y2 = int(p.top + 8*p.height) \n",
    "        mask[:, y1:y2, x1:x2] = 1\n",
    "\n",
    "        xmin = min(x1, xmin)\n",
    "        xmax = max(x2, xmax)\n",
    "        ymin = min(y1, ymin)\n",
    "        ymax = max(y2, ymax)\n",
    "\n",
    "\n",
    "    \"\"\"for i, p in hide_list.iterrows():\n",
    "        x1 = int(p.left - 1*p.width)\n",
    "        x2 = int(p.left + 2*p.width)\n",
    "        y1 = int(p.top)\n",
    "        y2 = int(p.top + 8*p.height) \n",
    "        mask[:, y1:y2, x1:x2] = 0\n",
    "    \"\"\"\n",
    "    \n",
    "    xmin = max(xmin,0)\n",
    "    xmax = min(xmax, img.shape[2])\n",
    "    ymin = max(ymin,0)\n",
    "    ymax = min(ymax, img.shape[1])\n",
    "    size = max((ymax-ymin), (xmax-xmin) )\n",
    "    \n",
    "    c, h, w = img.shape\n",
    "    res = torch.zeros((c, h + size, w + size))\n",
    "    res[:,:h, :w] = torch.masked_fill(img, mask==0, 0)\n",
    "    \n",
    "    \n",
    "    return res[:, ymin:ymin+size, xmin:xmin+size, ]\n",
    "\n",
    "    \n",
    "class PlayerContactDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tracking_features , helmets = None, transform = None, \n",
    "                 keys=keys, features= features, image_data=None, pad_value=-100):\n",
    "        super().__init__()\n",
    "        self.features= features\n",
    "        self.transform = transform\n",
    "        self.df = tracking_features\n",
    "        self.image_data = image_data\n",
    "        self.load_image = image_data is not None\n",
    "        self.helmets = helmets\n",
    "        self.pad_value = pad_value\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "        X = torch.tensor(row[self.features].tolist()[-9:]).T\n",
    "        \n",
    "        res = {\n",
    "            'contact_id': row.contact_id,\n",
    "            'X': X,\n",
    "            'label': torch.tensor(row.contact),\n",
    "        }\n",
    "        \n",
    "        if self.load_image:\n",
    "            imgs = torch.zeros((len(row.frame)*2,3, 224, 224))\n",
    "\n",
    "            for f_id, frame in enumerate(row.frame):\n",
    "                try:\n",
    "                    players = self.helmets.loc[(row.game_play, frame)]\n",
    "                except KeyError:\n",
    "                    players = None\n",
    "                    \n",
    "                if players is not None:  \n",
    "                    for z_id, zone in enumerate(['Endzone', 'Sideline']):\n",
    "\n",
    "                        idx = path2index.get(f'{row.game_play}_{zone}_{frame}')\n",
    "\n",
    "                        if idx:\n",
    "                            img = self.image_data[idx]['image']\n",
    "                            img = crop_players(img,row.nfl_player_id_1, row.nfl_player_id_2, row.game_play, players, zone)\n",
    "                            \n",
    "                            imgs[f_id*2+z_id]=transforms.functional.resize(img,[224,224])\n",
    "                        \n",
    "            res['imgs'] = imgs.div(255)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                res['imgs'] = self.transform(res['imgs'])\n",
    "                    \n",
    "\n",
    "        return res\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _pad(self, seq, key):\n",
    "        if torch.is_tensor(seq[0]):\n",
    "            if key == 'imgs':\n",
    "                pad_val = 0\n",
    "            elif key =='label':\n",
    "                pad_val = -100\n",
    "            else:\n",
    "                pad_val = self.pad_value\n",
    "                \n",
    "            res = pad_sequence(seq,batch_first=True, padding_value=pad_val)\n",
    "        else:\n",
    "            max_lenght = max(len(_) for _ in seq)\n",
    "            res = [_ + (max_lenght-len(_))*[self.pad_value] for _ in seq]\n",
    "        return res\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        values = zip(*[b.values() for b in batch])\n",
    "        keys = batch[0].keys()\n",
    "        return {k: self._pad(v, k) for k, v in zip(keys, values)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330c4b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:54:35.166231Z",
     "iopub.status.busy": "2023-02-22T20:54:35.165480Z",
     "iopub.status.idle": "2023-02-22T20:54:42.027174Z",
     "shell.execute_reply": "2023-02-22T20:54:42.026225Z"
    },
    "papermill": {
     "duration": 6.868455,
     "end_time": "2023-02-22T20:54:42.029685",
     "exception": false,
     "start_time": "2023-02-22T20:54:35.161230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#create_tracking_features\n",
    "tracking = pd.read_csv('/kaggle/input/nfl-player-contact-detection/test_player_tracking.csv').astype({'nfl_player_id': str})\n",
    "tracking['frame'] = (59.94*0.1*tracking['step'] + 5*59.94).astype(int)\n",
    "positions = tracking.position.unique().tolist()\n",
    "positions = {p: i for i, p in enumerate(positions)}\n",
    "tracking['position'] = tracking['position'].apply(lambda x: positions[x])\n",
    "\n",
    "\n",
    "labels = pd.read_csv('/kaggle/input/nfl-player-contact-detection/sample_submission.csv')\n",
    "\n",
    "def split_fn(x):\n",
    "    x = x.split('_')\n",
    "    return [f'{x[0]}_{x[1]}'] + x[2:]\n",
    "\n",
    "\n",
    "labels = pd.concat([labels, pd.DataFrame(\n",
    "                    labels.contact_id.apply(split_fn).tolist(),\n",
    "                    columns =['game_play', 'step', 'nfl_player_id_1', 'nfl_player_id_2']\n",
    "                ).astype({'step': int, 'nfl_player_id_1': str, 'nfl_player_id_2': str})],\n",
    "          axis=1)\n",
    "\n",
    "\n",
    "tf= create_tracking_features(labels, tracking, chank_size=20)\n",
    "\n",
    "\n",
    "# filtering \n",
    "dataset = PlayerContactDataset(tf)\n",
    "\n",
    "filter_model=  FilterGRU().from_pretrained('/kaggle/input/models/filter').to(device)\n",
    "\n",
    "def dummy_loss(*args, **kwargs):\n",
    "    return torch.tensor(0.)\n",
    "\n",
    "def get_probas(logits, label, **kwargs):\n",
    "    \n",
    "    y_pred = (logits.softmax(-1)[:,1:].sum(-1)>0.2).type(torch.uint8)\n",
    "    y_true = (label.max(-1)[0]>0).type(torch.uint8)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "trainer = Trainer(\n",
    "    dataset,\n",
    "    dataset,\n",
    "    model = filter_model,            \n",
    "    batch_size = 1000,\n",
    "    num_epoch = 1,\n",
    "    loss_fn = dummy_loss,\n",
    "    post_procc_fn = get_probas\n",
    ")\n",
    "\n",
    "result = trainer.evaluation()[1]                         \n",
    "dataset.df = dataset.df[np.array(result['preds'])==1]\n",
    "tf =dataset.df\n",
    "\n",
    "frames4extract = tf[['game_play', 'frame']].groupby('game_play', as_index = False).agg(sum)\n",
    "frames4extract.loc[:,'frame'] = frames4extract.frame.apply(lambda x: set(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92ec1f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:54:42.038586Z",
     "iopub.status.busy": "2023-02-22T20:54:42.038276Z",
     "iopub.status.idle": "2023-02-22T20:55:09.406828Z",
     "shell.execute_reply": "2023-02-22T20:55:09.405802Z"
    },
    "papermill": {
     "duration": 27.375573,
     "end_time": "2023-02-22T20:55:09.409182",
     "exception": false,
     "start_time": "2023-02-22T20:54:42.033609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.07s/it]\n",
      "100%|██████████| 1/1 [00:17<00:00, 17.87s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9409a71e3549e0a81a96034a348294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#image data\n",
    "extract_parallel(frames4extract, '/kaggle/input/nfl-player-contact-detection/test', 'frames')\n",
    "image_data, path2index, index2path = create_image_dataset('frames', transform = transforms.Resize(256))\n",
    "\n",
    "#load helmets data\n",
    "h,w = image_data[0]['image'].shape[1:]\n",
    "\n",
    "helmets = pd.read_csv('/kaggle/input/nfl-player-contact-detection/test_baseline_helmets.csv').astype({'nfl_player_id': str})\n",
    "helmets['key'] = helmets.apply(lambda x: f\"{x['game_play']}_{x['view']}_{x['frame']}\", axis=1)\n",
    "\n",
    "helmets.loc[:, ['left', 'width']] = (helmets.loc[:, ['left', 'width']]*w/1280).astype(int)\n",
    "helmets.loc[:, ['top', 'height']] = (helmets.loc[:, ['top', 'height']]*h/720).astype(int)\n",
    "\n",
    "helmets = pd.DataFrame({'key': path2index.keys()}).merge(helmets)\n",
    "helmets = helmets.set_index(['game_play', 'frame']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec84b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:55:09.421283Z",
     "iopub.status.busy": "2023-02-22T20:55:09.419780Z",
     "iopub.status.idle": "2023-02-22T20:55:09.426274Z",
     "shell.execute_reply": "2023-02-22T20:55:09.425427Z"
    },
    "papermill": {
     "duration": 0.014267,
     "end_time": "2023-02-22T20:55:09.428431",
     "exception": false,
     "start_time": "2023-02-22T20:55:09.414164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "std=np.array([0.229, 0.224, 0.225])\n",
    "mean=np.array([0.485, 0.456, 0.406])\n",
    "\n",
    "transform = nn.Sequential(\n",
    "    transforms.Normalize(std=std, mean=mean)\n",
    ")\n",
    "\n",
    "train_size = int(len(tf)*0.9)\n",
    "\n",
    "dataset = PlayerContactDataset(\n",
    "    tf, pad_value=0, transform = transform, \n",
    "    image_data=image_data, helmets = helmets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba496c",
   "metadata": {
    "papermill": {
     "duration": 0.004103,
     "end_time": "2023-02-22T20:55:09.436778",
     "exception": false,
     "start_time": "2023-02-22T20:55:09.432675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3237beff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:55:09.447034Z",
     "iopub.status.busy": "2023-02-22T20:55:09.446762Z",
     "iopub.status.idle": "2023-02-22T20:55:09.464183Z",
     "shell.execute_reply": "2023-02-22T20:55:09.463130Z"
    },
    "papermill": {
     "duration": 0.02504,
     "end_time": "2023-02-22T20:55:09.466246",
     "exception": false,
     "start_time": "2023-02-22T20:55:09.441206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import math\n",
    "from models.pretrained_model import PreTrainedModel\n",
    "\n",
    "a= [1]\n",
    "\n",
    "class X3D_GRU(nn.Module):\n",
    "    def __init__(self, \n",
    "            x3d_kwargs = {\n",
    "                'repo_or_dir' :'pytorchvideo',\n",
    "                'model': 'x3d_s',\n",
    "                'source': 'local', \n",
    "                'pretrained': False\n",
    "            }\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.x3d = torch.hub.load(**x3d_kwargs)\n",
    "        self.x3d.blocks[5]= nn.Identity()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        num_features = list(self.x3d.blocks[4].res_blocks.modules())[-2].num_features*2\n",
    "        \n",
    "        self.gru = nn.GRU(input_size =num_features, hidden_size=num_features, num_layers=3, \n",
    "                          bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(num_features*2,3)\n",
    "        \n",
    "          \n",
    "    def forward(self, imgs,  **kwargs):\n",
    "        \n",
    "        f = self.x3d(imgs.permute(0,2,1,3,4))\n",
    "        \n",
    "        f = self.pool(f)\\\n",
    "            .squeeze(-1).squeeze(-1)\\\n",
    "            .permute(0,2,1)\\\n",
    "            .reshape(f.shape[0], f.shape[2]//2, -1 )\n",
    "        \n",
    "        X, h = self.gru(f)\n",
    "        return self.fc(X)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)\n",
    "                        * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "\n",
    "class TransformerTracker(PreTrainedModel):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Linear(9,256)\n",
    "        self.positional_encoding = PositionalEncoding(256, dropout=0.1)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=4, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
    "        self.fc = nn.Linear(256,3)\n",
    "        self.x3d = X3D_GRU()\n",
    "        self.x3d.fc = nn.Linear(768,256)\n",
    "\n",
    "        \n",
    "    def forward(self, X, imgs,  **kwargs):\n",
    "            \n",
    "        X = self.positional_encoding(self.upsample(X))\n",
    "        X = self.transformer_encoder(X)\n",
    "        try:\n",
    "            imgs = self.x3d(imgs)\n",
    "        except:\n",
    "            a[0] = imgs.cpu().numpy()\n",
    "        \n",
    "        return self.fc(X+imgs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5bd6f",
   "metadata": {
    "papermill": {
     "duration": 0.004143,
     "end_time": "2023-02-22T20:55:09.474713",
     "exception": false,
     "start_time": "2023-02-22T20:55:09.470570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53114b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:55:09.485640Z",
     "iopub.status.busy": "2023-02-22T20:55:09.484204Z",
     "iopub.status.idle": "2023-02-22T20:55:58.898104Z",
     "shell.execute_reply": "2023-02-22T20:55:58.897124Z"
    },
    "papermill": {
     "duration": 49.421895,
     "end_time": "2023-02-22T20:55:58.900804",
     "exception": false,
     "start_time": "2023-02-22T20:55:09.478909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TransformerTracker().from_pretrained('/kaggle/input/models/contact_detector').to(device)\n",
    "\n",
    "def post_procc(logits, label, **kawargs):\n",
    "    ids = label.flatten() != -100\n",
    "    y_pred = (1-logits.softmax(-1)[:,:,0]).flatten()[ids]\n",
    "    y_true = label.flatten()[ids]\n",
    "    return y_true, (y_pred>0.44).to(dtype=torch.int32) \n",
    "  \n",
    "trainer = Trainer(\n",
    "    dataset,\n",
    "    dataset,\n",
    "    model = model,            \n",
    "    batch_size = 4,\n",
    "    num_epoch = 1,\n",
    "    loss_fn = dummy_loss,\n",
    "    post_procc_fn = post_procc\n",
    ")\n",
    "\n",
    "result= trainer.evaluation()[1]\n",
    "\n",
    "df = pd.DataFrame({'contact_id': dataset.df.contact_id.agg(sum), 'preds': result['preds']})\n",
    "submission = pd.read_csv('/kaggle/input/nfl-player-contact-detection/sample_submission.csv')\n",
    "submission.contact = submission.merge(df, how='left')\\\n",
    "    .preds.fillna(0)\\\n",
    "    .astype(int)\n",
    "submission.loc[submission.contact==2, 'contact'] = 1\n",
    "submission.to_csv('submission.csv',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994a9710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T20:55:58.911057Z",
     "iopub.status.busy": "2023-02-22T20:55:58.910768Z",
     "iopub.status.idle": "2023-02-22T20:55:58.989174Z",
     "shell.execute_reply": "2023-02-22T20:55:58.988225Z"
    },
    "papermill": {
     "duration": 0.085825,
     "end_time": "2023-02-22T20:55:58.991369",
     "exception": false,
     "start_time": "2023-02-22T20:55:58.905544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for p in os.listdir('.'):\n",
    "    if p != 'submission.csv' and os.path.isdir(p):\n",
    "        shutil.rmtree(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.37132,
   "end_time": "2023-02-22T20:56:01.592305",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-22T20:54:19.220985",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "18c420e833f142f69c5b5440a8f6e5fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d584ed319f145469b848e7879ec25ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3104e06f7b934a58b9f995ac8f9b4d28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18c420e833f142f69c5b5440a8f6e5fb",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_847ec3f262f7430e9291d731bec114e6",
       "value": 1.0
      }
     },
     "6c79eaa0a4584fb6a5bd1a167b9f8e42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "721b912f8abd4454ab29e282a6120463": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7eee627e25894c00960e5ce9cc048299": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de2a1fb6e31d44dea495965b4186769a",
       "placeholder": "​",
       "style": "IPY_MODEL_6c79eaa0a4584fb6a5bd1a167b9f8e42",
       "value": "100%"
      }
     },
     "847ec3f262f7430e9291d731bec114e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b7600f565eb448ef9fc4ad60d366efe1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d584ed319f145469b848e7879ec25ab",
       "placeholder": "​",
       "style": "IPY_MODEL_721b912f8abd4454ab29e282a6120463",
       "value": " 1/1 [00:08&lt;00:00,  8.41s/ba]"
      }
     },
     "be9409a71e3549e0a81a96034a348294": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7eee627e25894c00960e5ce9cc048299",
        "IPY_MODEL_3104e06f7b934a58b9f995ac8f9b4d28",
        "IPY_MODEL_b7600f565eb448ef9fc4ad60d366efe1"
       ],
       "layout": "IPY_MODEL_fc0177970f9c45ae9294e930710cca54"
      }
     },
     "de2a1fb6e31d44dea495965b4186769a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc0177970f9c45ae9294e930710cca54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
